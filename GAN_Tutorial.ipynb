{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "GAN Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmaguo13/ml-fundies/blob/main/GAN_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MX46K-3E3HQ"
      },
      "source": [
        "# Training a GAN on Mnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkZ8oIpIE3Ha"
      },
      "source": [
        "from typing import Tuple\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import wandb #if you dont have wandb setup, please install it and ask divi for the login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBPWhapPE3Hb"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# so you dont have to restart kernel if you make changes to other files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf5M1vDpE3Hb"
      },
      "source": [
        "For the first part of this notebook, we are going to create the Generator model and the Descriminator model.\n",
        "\n",
        "For a simple example of how to do this, check models.py in the accompanying repo. The models in this file are just one layer -- we would like to train a model that is larger than this so that it will do better.\n",
        "\n",
        "## Generator\n",
        "This is the model that will take in random noise and output an image. We will decide the size of the random noise and images later on in this notebook, so just make sure your model will take in a vector of size `input_length` and output an image of size `output_length`. Ensure your model has multiple layers, but the design of the rest of the model is up to you. If you choose to train on larger images, (Ex: 64x64 or 128x128) consider using some deconvolutional layers.\n",
        "\n",
        "## Descriminator\n",
        "This is the model that will take in an image and output a probability that this image is real. Thus, it will take in an image of size `output_length` and output 1 value. You can think of this as just a binary classification model (therefore we will train on binary cross entropy). As before, create your Discriminator model with multiple layers and the correct input and output sizes. If you choose to train on larger images, (Ex: 64x64 or 128x128) consider using some convolutional layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEApEG3HE3Hc"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_length: int, output_length: int):\n",
        "        super(Generator, self).__init__()\n",
        "        # TODO instantiate the layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO pass x through the layers + activations and return it\n",
        "        return\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_length: int):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # TODO instantiate the layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO pass x through the layers + activations and return it\n",
        "        return \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWl6NOBTE3Hd"
      },
      "source": [
        "# Loading the Dataset\n",
        "For this notebook, we are going to train on the CelebA dataset in order to create pictures of faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "e0Uip2OqE3He"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CelebA, MNIST\n",
        "import torchvision.transforms as transforms \n",
        "\n",
        "# TODO fill in these parameters with whatever you want\n",
        "image_size = None # should be a tuple\n",
        "batch_size = None\n",
        "\n",
        "# first we create some transforms to normalize our data and resize it to the shape that we specify\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# this will download the celeba dataset for you, if it doesn't work\n",
        "# then find it online\n",
        "dataset = MNIST(\"~/datasets\", train=True, download=True, transform=transform)\n",
        "data_loader = DataLoader(dataset=dataset, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmY5ogtME3He"
      },
      "source": [
        "Now lets look at some of the images we will be training on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "iOTwDJ9tE3He"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "samples, label = next(iter(data_loader))\n",
        "sample = samples[0].numpy().transpose(1,2,0) #pytorch has channels as first dim, we need it as last dim\n",
        "\n",
        "plt.imshow(sample, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(label[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWU8td0fE3Hf"
      },
      "source": [
        "Now that we have loaded our dataset and decided our image size, lets instantiate our generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fbGxDAM_E3Hf"
      },
      "source": [
        "# Choose the size of the noise vector to give to our generator\n",
        "input_length = None\n",
        "\n",
        "# Instantiate Models\n",
        "generator = None\n",
        "discriminator = None\n",
        "\n",
        "# It is always good to print out your model \n",
        "# to make sure it is what you are expecting\n",
        "print(generator)\n",
        "print(discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uZruFjJE3Hf"
      },
      "source": [
        "# sanity check to make sure your shapes are correct\n",
        "outputs = generator(torch.zeros(batch_size, input_length))\n",
        "outputs = outputs.view(batch_size, 1, image_size[0], image_size[1])\n",
        "fake_prob = discriminator(outputs)\n",
        "\n",
        "# visualize the image created by an untrained generator, this should look like noise\n",
        "output = outputs[0].detach().numpy().transpose(1,2,0)\n",
        "plt.imshow(output, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld5VqdCvE3Hg"
      },
      "source": [
        "## Optimizers\n",
        "We need two optimizers to train our two models. Choose the learning rate for these below. Feel free to experiment with these!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxOEUZNcE3Hg"
      },
      "source": [
        "generator_learning_rate = None\n",
        "discriminator_learning_rate = None\n",
        "\n",
        "# Create optimizers with the learning rates of your chooosing\n",
        "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=generator_learning_rate)\n",
        "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=discriminator_learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iDzAAkKE3Hg"
      },
      "source": [
        "## Training\n",
        "Now we have everything we need to train our GAN! Except the training loop. Fill in the missing code. Once you're done, run the cells below to train your GAN and checkout wandb to see how it is doing!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa42UyPHFrJq"
      },
      "source": [
        "def train(\n",
        "    generator,\n",
        "    discriminator,\n",
        "    generator_optimizer,\n",
        "    discriminator_optimizer,\n",
        "    data_loader,\n",
        "    batch_size,\n",
        "    input_length,\n",
        "    img_shape: tuple,\n",
        "    epochs: int = 3,\n",
        ") -> Tuple[nn.Module]:\n",
        "    \"\"\"Trains the even GAN\n",
        "\n",
        "    Args:\n",
        "        batch_size: The number of examples in a training batch\n",
        "        epochs: The number of epochs to train for.\n",
        "\n",
        "    Returns:\n",
        "        generator: The trained generator model\n",
        "        discriminator: The trained discriminator model\n",
        "    \"\"\"\n",
        "    # loss is binary cross entropy loss\n",
        "    loss = nn.BCELoss()\n",
        "    img_w = img_shape[0]\n",
        "    img_h = img_shape[1]\n",
        "\n",
        "    for i in range(epochs):\n",
        "        for sample in data_loader:\n",
        "            # zero the gradients on each iteration\n",
        "            generator_optimizer.zero_grad()\n",
        "\n",
        "            # Here we create the noise input for generator and pass it through the generator to create our fake data\n",
        "            noise = torch.randint(0, 2, size=(batch_size, input_length)).float()\n",
        "            generated_data = generator(noise)\n",
        "            generated_data = generated_data.view(batch_size, 1, img_w, img_h) # resize to be image shape with channel 1\n",
        "\n",
        "            # Here we get real data\n",
        "            true_data = sample[0]\n",
        "            # TODO: create the labels for the true data, this should be a tensor of size batch_size.\n",
        "            # Remember we are doing binary classification here.\n",
        "            true_labels = None\n",
        "\n",
        "            # TODO: Train the generator\n",
        "            # AKA do a forward pass and get the loss (loss function is defined above)\n",
        "            # We invert the labels here and don't train the discriminator because we want the generator\n",
        "            # to make things the discriminator classifies as true.\n",
        "            generator_discriminator_out = None\n",
        "            generator_loss = None\n",
        "            \n",
        "            # Notice that we do not call .step on the discriminator_optimizer\n",
        "            # This is so that we do not update the parameters of the discriminator when training the generator\n",
        "            generator_loss.backward()\n",
        "            generator_optimizer.step()\n",
        "\n",
        "            # TODO: Train the discriminator on the true data\n",
        "            # AKA do a forward pass and get the loss on the true data\n",
        "            # We don't invert the labels here, why?\n",
        "            discriminator_optimizer.zero_grad()\n",
        "            true_discriminator_out = None\n",
        "            true_discriminator_loss = None\n",
        "\n",
        "            # Now we do a forward pass using the fake data and get the loss with inverted labels\n",
        "            # We add .detach() here so that we do not backprop into the generator when we train the discriminator\n",
        "            # if you're not sure what this does, thats ok! ask us we love to answer questions\n",
        "            generator_discriminator_out = discriminator(generated_data.detach())\n",
        "            generator_discriminator_loss = loss(generator_discriminator_out, torch.zeros(batch_size))\n",
        "            discriminator_loss = (true_discriminator_loss + generator_discriminator_loss) / 2\n",
        "            \n",
        "            discriminator_loss.backward()\n",
        "            discriminator_optimizer.step()\n",
        "            \n",
        "            wandb.log({\"Generator Loss\": generator_loss, \n",
        "                    \"Discriminator Loss (on real images)\" : true_discriminator_loss,\n",
        "                    \"Discriminator Loss (on fake images)\": generator_discriminator_loss,\n",
        "                    \"Discriminator Guess (on fake images)\": torch.mean(generator_discriminator_out),\n",
        "                    \"Discriminator Guess (on real images)\": torch.mean(true_discriminator_out)})\n",
        "\n",
        "    return generator, discriminator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD3-HmE2E3Hh"
      },
      "source": [
        "wandb.init(project='gan-notebook')\n",
        "\n",
        "# fill in a name to keep track of which wandb runs are yours\n",
        "your_name = None\n",
        "wandb.config.name = your_name\n",
        "\n",
        "# fill in the number of epochs you want to train for\n",
        "epochs = 10\n",
        "wandb.config.epochs = epochs\n",
        "\n",
        "trained_generator, trained_discriminator = train(generator, discriminator, \n",
        "                                                 generator_optimizer, discriminator_optimizer, \n",
        "                                                 data_loader, batch_size,\n",
        "                                                 input_length, image_size, epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKyR1ZOtE3Hh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}